Title: Should free speech protections be expanded, to any extent, to social media platforms?

Post:
I've seen a lot of people make the argument that the first amendment only protects against government censorship. However, I have seen very little discussion on whether or not it should be this way.

we wouldn't have predicted the amount of influence social media now has 20 years ago, let alone when the 1st amendment was drafted. The constitution is an imperfect document that was meant to be changed with the times. Perhaps free speech protections should be one of those changes?

I don't believe I have any problem with social media companies removing blatant misinformation, but what is stopping facebook/google from going further? what if the next ceo of facebook is an avid climate denier and decided any/all posts relating to climate change will be removed on the platform (as an extreme example)?. should there be any protections against this sort of thing? If so, how far should these protections go?

even if only "misinformation" is removed, who gets to decide what is or isn't misinformation? should we be trusting facebook/google employees to be unbiased in determining what is true? 


I don't have a well thought out opinion on this issue, but I would love to see some nuanced discussion on this topic.

Top Comments:
[A reminder for everyone](https://www.reddit.com/r/PoliticalDiscussion/comments/4479er/rules_explanations_and_reminders/). This is a subreddit for genuine discussion:

* Please keep it civil. Report uncivil or meta comments for moderator review.
* Don't post low effort comments like joke threads, memes, slogans, or links without context.
* Help prevent this subreddit from becoming an echo chamber. Please don't downvote comments with which you disagree.

Violators will be fed to the bear.

---

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PoliticalDiscussion) if you have any questions or concerns.*
The only way this would work is if you nationalized social media companies, and I just don't think that's what anyone wants
> If I own a megaphone should the government make me hand it to everyone who wants it, even if I disagree with what they have to say

This is fundamentally no different from what you've asked. Social media is not the only way to reach an audience. Social media is not a public service. I don't owe you a megaphone. Facebook doesn't owe you a platform. 

If Facebook wants to deplatform people who acknowledge the reality of climate change, they're free to do so. It's probably a bad call for their business, but the state has absolutely no basis for stopping them and they shouldn't.
If the government can't regulate online speech platforms, do they have a duty to 

A) Provide some sort of "guaranteed free" alternative platform online to ensure that there's at least one?

B) Provide "assessing the accuracy of online information" as a component of a public education?

I might expand this with a follow-up post.
Expanding them to social media companies by definition means limiting them for social media companies. Part of free speech is being able to define what speech exists on your property, in your business, on your platform, etc.

Forcing people to tolerate speech they don't like in their own space is the other side of this coin.

EDIT: Expanding answer

> I don't believe I have any problem with social media companies removing blatant misinformation, but what is stopping facebook/google from going further?

Their concern over their stock price and the threat of users moving elsewhere if they abuse their control of their platform.

And they can die. I'm tired of pretending like the Internet consists entirely of Facebook, Google, Twitter, and YouTube. Remember MySpace? Remember Digg? Social media companies can die out if their users leave. And the Internet consists of literally billions of web pages that anyone can access to spread their message. The barrier to entry if your goal is merely to speak your mind is incredibly low. Social media companies just make it easier to find an audience, but free speech doesn't guarantee you that.

I mean leaving these sites is literally what many right wingers mad about censorship do, and they go form their own sites. The only difference is that usually those sites start being inundated with material that makes it obvious why those people were censored or banned, like Voat, the "censorship-free" alternative to Reddit that quickly became filled with racism and anti-Semitism.

If Twitter decided to ban talk of climate change, pretty sure a lot of people would leave, and the site they went to wouldn't be a racist hellhole.

> even if only "misinformation" is removed, who gets to decide what is or isn't misinformation? should we be trusting facebook/google employees to be unbiased in determining what is true? 

No, you shouldn't. This is why critical thinking and research skills are super important, and it's a failure of our education system that more people don't have information literacy.
> I don't believe I have any problem with social media companies removing blatant misinformation, but what is stopping facebook/google from going further? what if the next ceo of facebook is an avid climate denier and decided any/all posts relating to climate change will be removed on the platform (as an extreme example)?. should there be any protections against this sort of thing? If so, how far should these protections go?

We *have* protections for this. It's called the free market. If a site goes overboard with its moderation decisions, they would be punished for that by their users when they go to other services. The government doesn't need to ensure this doesn't happen because there's already substantial market pressures preventing it. 

Which is not to say we should go completely libertarian. The government's role here is important, actually: ensure that the digital economy is full of robust, strong competition in every area. That way, when a service makes poor decisions, users have ample alternatives they can migrate to to punish those poor decisions.
The fact that the government is flagging posts/users for removal I would argue this becomes a first amendment issue. Now if they were not involved at all, I would say there is no first amendment issue, but....if they start to censor on their own platforms, then they shouldn't be protected by 231. If they don't censor, then 231 protection should be afforded. Right now, they get have their monopoly government backed cake and eat it too. We have already seen that the "fact checkers" have been completely wrong, and still had no penalty. The ministry of truth gets closer every day......1984 was a warning, not a guide book.
Social media are private corporations and can choose how to run their business and who to do business with. Free enterprise is beautiful.
Yes. No matter what; yes. If we as humans are too dumb to sort misinformation from information then that’s honestly the least of our problems and we have much much larger issues than if we were fooled by something we’ve read online/or anywhere else