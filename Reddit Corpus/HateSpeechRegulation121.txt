Title: ‘The work damaged me’: ex-Facebook moderators describe effect of horrific content | Former workers at Samasource say violent, graphic and sexually explicit videos left them fearful to go outside

Post:


Top Comments:
Worked for a third party that did the same thing. The Inidan branch came down with Covid and they were no longer operational. We had to go through all the suicide content for a month. Loads of people quit because they couldn't handle it (rightfully so). The only way I did was by not looking directly at my screen and actioning the jobs in a mix of indicators as soon as the vibe hit. You never knew the outcome of these people but I know I watched some of their last moments on live. I became very good at "not taking my work home" with me as well as overwriting certain memories. It was very grim and depressing. I've seen pretty much anything you can imagine and it does leave a mark. 
Some of the troubling details:

>“I thought I was one of the lucky ones,” the 26-year-old, said. But then he found himself ploughing through heaps of violent and sexually explicit material, including grisly accidents, suicides, beheadings and child abuse.
>
>...
>
>He had been hired by Samasource to moderate Facebook content, weeding out the most toxic posts. Some of the most tormenting images remained etched in his mind, occasionally jolting him awake in night sweats. Fearing that opening up about his work would evoke discomfort, concern or judgment from others, he kept it to himself.
>
>Exasperated by his “secretiveness”, his wife grew distant. Irungu resigned himself to them drifting apart, convinced he was protecting her and stayed in the job for three years. He says he regrets pressing on.
>
>“I don’t think that work is suitable for human beings,” he said. “It really isolated me from the real world because I started to see it as such a dark place.” He became afraid to let his daughter out of his sight.
>
>“When I ask myself if the money was really worth sacrificing my mental health for, the answer is no.”
>
>...
>
>She remembered once screaming in the middle of the office floor after watching one horrific scene. Except for a few glances from co-workers, and a team leader pulling her aside to “go to wellness” counselling, it was like nothing had happened, she said. The wellness counsellors told her to take some time to rest and get the image out of her head.
>
>“How do you forget when you’re back on the floor after a 15-minute break, to move to the next thing?” she said. She wondered if the counsellors were qualified psychotherapists, saying that they would never escalate a case for mental healthcare no matter what the moderators had seen or how distressed they were.

Sadly this is not the first, nor is it likely to be the last, report of human moderators suffering from the content that they are reviewing. Tech companies want us to believe that everything they provide is clean and fresh and organized and consequence free, but as we see in cases like these there are always people who are shouldering the burdens imposed by these platforms.
And many people seem to want no such moderation at all on websites.  "Free speech!" they say.  Ok, great, now we *all* have to sort through this stuff just to browse the Reddit subs related to our hobbies.
I saw ONE THING about 10 years ago.  ONE THING.  ...reading this brought it back; it took forever to forget it.  This is not ok for people's mental health.  They won't be the same for years.
You gotta hire grizzled internet veterans for this. People who cut their teenage teeth on Rotten.com, surprise Limewire downloads, graduated to Ogrish and ConsumptionJunction, and were saddened by the banning of /r/spacedicks and /r/watchpeopledie. 

You can’t just hire Gen-Z whippersnappers for this kind of thing. You need wild-west grizzled veterans with the ICQ, SubSeven, and Napster badges pinned to their uniforms.
A lot of people saying AI should do it then. To me that cannot be the answer. It still needs proper training and will most likely be faulty. We just need checks I guess for who can do the job. Someone has to do it , it is like army training.
My wife’s Facebook got hacked. Hundreds of pedo images, isis beheadings, murders and all sort of shit were posted. Obviously her account was muted, and we had to verify some of the images were not us, for reasons I still don’t understand. But put it this way, fuck doing that for a job!
It might not be sufficient to have this be moderation, maybe it should include wellness checks for the people posting this kind of stuff because they can't be healthy.