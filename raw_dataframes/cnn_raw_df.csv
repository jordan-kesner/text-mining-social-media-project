,Label,Content
0,Hate Speech Regulation,"Calling women ‘household objects’ now permitted on Facebook after Meta updated its guidelines

---

Meta on Tuesday announced sweeping changes to how it moderates content that will roll out in the coming months, including doing away with professional fact checking. But the company also quietly updated its hateful conduct policy, adding new types of content users can post on the platform, effective immediately.
Users are now allowed to, for example, refer to “women as household objects or property” or “transgender or non-binary people as ‘it,’” according to a section ofthe policyprohibiting such speech that was crossed out. A new section of the policy notes Meta will allow “allegations of mental illness or abnormality when based on gender or sexual orientation, given political and religious discourse about transgenderism and homosexuality.”
Previously, such comments would have been subject to removal under the policy. The changes to Meta’s hateful conduct policy werefirst reportedby Wired.
Meta had hinted in its announcement about its content moderation policy changes Tuesday morning that it would get rid of restrictions on certain topics, such as immigration and gender identity, and allow more political discussions. But the updated policy shows just how quickly Meta is moving to enact CEO Mark Zuckerberg’s vision for “free expression.”
Related articleMeta is getting rid of fact checkers. Zuckerberg acknowledged more harmful content will appear on the platforms now
Meta on Tuesday also announced it would do away with its network of independent fact checkers in the United States and will instead rely on user-generated “community notes” to add context to posts. It also said it would adjust its automated systems that scan for policy violations, which it says have resulted in “too much content being censored that shouldn’t have been.” The systems will now be focused only on extreme violations such as child sexual exploitation and terrorism.
Zuckerberg acknowledged that the new approach will mean “that we’re going to catch less bad stuff, but we’ll also reduce the number of innocent people’s posts and accounts that we accidentally take down.”
A Meta spokesperson noted that the company will continue to prohibit attacks against certain groups, such as those based on ethnicity, race and religion, as well as prohibiting slurs, under the policy. And the spokesperson said that the company will continue enforce its policies against targeted bullying and harassment, as well asincitement of violence.
The company’s Tuesday changes come as the company and its leader have sought to curry favor with Donald Trump and other Republicans ahead of the president-elect’s second term, echoing in its announcement longstanding criticisms that Meta was “censoring” conservative voices.
Trumpwelcomedthe changes in a press conference Tuesday and said he thinks the changes are “probably” due to threats he’s made to Zuckerberg in the past. But some experts who study the online information ecosystem raised alarms that the changes could lead to more viral false claims and hate speech on Meta’s platforms.
Among the other changes to Meta’s hateful conduct policy, the company removed a prohibition against statements denying the existence of “protected” groups, such as statements that a certain group of people doesn’t or shouldn’t exist. The policy also now allows for content arguing in favor of “gender-based limitations of military, law enforcement, and teaching jobs.”
The company also updated its “misinformation” policy to note the dissolution of its US-based fact-checking network."
1,Hate Speech Regulation,"Disinformation experts blast Trump’s executive order on government censorship as ‘direct assault on reality’

---

One of President Donald Trump’s first actions as he returned to the Oval Office on Monday was signing an executive order aimed at “restoring freedom of speech and ending federal censorship” of US citizens.
The order bans federal officials from any conduct that “would unconstitutionally abridge the free speech of any American citizen” and instructs the attorney general to investigate if the Biden administration engaged in efforts to censor Americans.
“Under the guise of combatting ‘misinformation,’ ‘disinformation,’ and ‘malinformation,’ the Federal Government infringed on the constitutionally protected speech rights of American citizens across the United States in a manner that advanced the Government’s preferred narrative about significant matters of public debate,” the order states.
Right-wing media figures and some Republicans in Congress have for years decried what they claim are efforts by Democrats and technology platforms to censor their speech online, especially around the Covid-19 pandemic and elections. The Supreme Courtruled last yearthe US government can contact social media companies about mis- and disinformation swirling on their platforms, handing the Biden administration a major victory.
Related live-storyTrump seeks to reshape US government with sweeping executive actions
While conservatives viewed Trump’s order as the fulfillment of his promise to end government collusion with Big Tech platforms to censor their voices, some disinformation experts warned the move will only further the spread of false information on social media, which can become dangerous in times of crises.
Nina Jankowicz, who briefly led the Biden administration’s disinformation board and is now CEO of the American Sunlight Project, said Trump’s order “has canonized lies and conspiracy theories about those responding to disinformation,” calling it “a direct assault on reality” that “emboldens both foreign actors and disinformation profiteers.”
“Disinformation is not a partisan issue; it’s a democracy issue,” she said. “America’s adversaries benefit when our country is internally divided and politically polarized.”
Other experts pointed out that the order could have a chilling effect on relations between government agencies and tech platforms, potentially harming national security.
“The vast majority of tech-government contact is not around political speech but is around areas of national security and fighting financial fraud and child sexual abuse material,” said John Wihbey, an associate professor of media innovation and technology at Northeastern University.
While Wihbey said there are “legitimate concerns about government jawboning,” where the government uses pressure to silence speech, the important “pipeline between tech companies and the Department of Justice/FBI and intel communities will be impeded by this order.”
Most of the experts pointed out that Trump’s executive order may also be moot, since some of the biggest social media platforms have taken it upon themselves to eliminate professional fact checkers and drastically expand the type of language allowed on their services.
Earlier this month, Facebook and Instagram parent companyMeta announcedit would abandon its fact-checking program and loosen its “hateful policy” conduct to allow posts that call LGBTQ people “mentally ill.” The move came after Trump and other Republicans lambasted Meta and its CEO Mark Zuckerberg for what they decried as censorship of right-wing views.
Related articlePrince Harry claims ‘monumental victory’ after reaching settlement with The Sun publisher
Alex Abdo, litigation director of the Knight First Amendment Institute at Columbia University,warned thatTrump’s executive order could be used by the administration to engage in its own form of censorship by directing the attorney general to investigate the last administration’s actions.
The order “suggests that its goal is to rewrite history to suit its own agenda, and that it may itself become a vehicle for the new administration to engage in its own form of jawboning,” he said.
“There’s an alternative version of this executive order that would have been a genuine victory for free speech,” Abdo continued. “That version of the order would have directed the government to look at the evidence of jawboning in its own possession and across multiple contexts, and to follow the evidence where it leads. Unfortunately, that’s not what we got.”
Ending disinformation enforcement efforts could also lead to more abuse, said Alia Dastagir, a former USA Today reporter and author of a forthcoming book on women facing online harassment.
“(A)buse and harassment, which is often driven by disinformation, leads to less speech, to a collective silencing,” she said. “We cannot think of online abuse only as rape and death threats, but as the dissemination of lies that contribute to violence against some of the most vulnerable people in our society.”"
2,Hate Speech Regulation,"There’s a reason why it feels like the internet has gone bad

---

A version of this story appeared in CNN Business’ Nightcap newsletter. To get it in your inbox, sign up for freehere.
Facebook is full ofAI slop. X is full of “free thinkers” peddlingconspiracies. Google’s search results are telling us toeat rocks. More and more, it feels like the internet has gone bad.
There’s an increasingly popular theory about why: “enshittification.”
The term, coined in 2022 by theauthor, journalist and activist Cory Doctorow, refers broadly to the deterioration of services (especially online) as a result of giant companies extracting maximum profits from their customers. In a 2023 essay forWired, Doctorow laid out the basic arc of enshittification, or the process by which platforms die.
“First, they are good to their users; then they abuse their users to make things better for their business customers; finally, they abuse those business customers to claw back all the value for themselves. Then, they die.”
In other words: Products are good when they first hit the market, because companies need to lock in as many consumers as they can to achieve the huge scale they desire. Once everyone’s using the product, the company refocuses on creating value for business partners, padding its profit margins and letting the product corrode. Eventually, the company maxes out what it can extract from its business partners, too, and the whole thing fades into obsolescence.
Once you wrap your head around the idea, you start to see enshittification all around — not only online, but across the economy, in services that have beenpicked over by private equity(vet clinics,nursing homes,prisons, countlessotherindustries) or in the products peddled by highlyconcentrated industries. The Australian dictionary Macquarie even crowned it the2024 word of the year, noting its power to capture “what many of us feel is happening to the world and to so many aspects of our lives at the moment.”
On Tuesday, shortly after Meta’s CEO announced awidely criticized planto dispense with fact-checkers, I spoke with Doctorow about the future of social media and how “enshittification” can help us make sense of our collective online angst.
The following interview has been edited for length and clarity.
Nightcap:Could you give me your your cocktail-party-level introduction to “enshittification”?
Cory Doctorow:I think of enshittification as a theory about what happens when you have power without consequence.
We have increased the power available to large firms for a long time by reducing our antitrust enforcement, allowing mergers, predatory pricing, all the conduct that allows firms to get very big. That’s been across the board, not just with tech.
Nightcap:What does that look like, in real life?
Doctorow:There’s a law, the Digital Millennium Copyright Act, that makes it illegal to break digital rights management. So for example, if Audible (which is owned by Amazon) sells you one of my audiobooks, they require that it have digital rights management that locks it to Audible’s platform forever — you can’t unlock it, quit Audible and take your books with you.
And if I give you a tool to jailbreak the audiobook so you can go somewhere else, I commit a felony punishable by a five-year prison sentence and a $500,000 fine.
So even though I am the rights holder to that work, Amazon, the intermediary who sold you the work, has more intellectual-property rights to that work than I do.
This is a law that is oriented around allowing these large firms to wield regulation against competitors, against their own workforce and against their users so that they can maintain power. It’s a collapse of discipline — they don’t have to worry about their workers, they don’t have to worry about regulators. And they bought all their competitors.
Nightcap:Meta would seem like a kind of textbook case of enshittification. Facebook used to feel like a premium service, but the last few years it’s felt like it’s lost the plot.
Doctorow:Meta is a great example because they go through this pretty neat set of stages… They had this very straightforward value prop, which was like, just tell us who matters to you, and we’ll show you everything they post. And their pitch to the general public was, Facebook is like MySpace, but we won’t spy on you.
Nightcap:Right, that feels very much like aughts-era Facebook, when we could all just see our friends and enjoy the virtual connection. What changed?
Doctorow:Facebook at a certain point goes to publishers and says, create a Facebook page, post short excerpts to it, don’t worry about how many people follow you — we’re going to recommend it to users. So we’re going to show users things that they never asked to see in order to take some value away from them and give it to publishers.
You see the same thing with advertisers. Facebook not only offers to use surveillance data to benefit advertisers in the form of targeting, but they also invest heavily in anti-ad-fraud and in services to advertisers. So if your ads are not performing, they’ll help you figure it out, but also, if someone’s ripping you off, they’ll help you get your money back.
And so you see the users getting locked in by each other. They’re providing so much value to each other that they can’t bring themselves to leave, even as the service is getting monotonically worse.
And that’s as far as I think a lot of people take it — “Facebook’s got a mind control ray, they’re hacking your dopamine loops, and you can’t escape Facebook and they’re gonna sell you to advertisers.”
The evidence for “hacking your dopamine loops” is pretty thin. There’s much better evidence that people just care about their friends more than they hate Mark Zuckerberg, and so they stay there.
Nightcap:Your theory adds a third step here, where Facebook also turns its back on advertisers, too?
Doctorow:Right, once the advertisers were fully committed to a Facebook strategy, advertising got way more expensive and the amount of ad fraud you got was crazy. So the advertisers are getting screwed, the publishers are getting screwed, the end users are getting screwed.
Nightcap:I’m not asking you to look into a crystal ball here, but if you had to speculate, what’s next for Facebook or other decaying platforms?
Doctorow:Zuckerberg is insulated from the consequences of making bad choices until he’s not, right? Until things reach a breaking point, and then he tends to panic. Tech calls these panics “pivots,” but they’re just the outcome of being the CEO of a company that posts anemic growth or even a contraction in its user base and sees (Wall Street) just go nuts on you.
First, it was the Metaverse… which is like a not-very-successful video game that they spent billions on. Zuck could do that because he controls the majority of the voting shares and because he had huge cash reserves.
And now we’re seeing these weird announcements that they’re going to haveAI -generated userswho are going to interact with you. This is, again, a visibly terrible idea.
It could be a way to continue to post growth if users will tolerate it. But the equilibrium that Zuck has shot for, with Facebook and with Instagram, has been a service that is nearly so bad that people want to leave.
The anthropologist danah boyd describes how in the last days of MySpace, she could see how when one person who a lot of people talk to would leave, then a whole bunch of people would follow. It wasn’t the only reason they were there, but it was the last thing keeping them there, and then,boom, the bottom falls out and the net just starts to unravel.
This is where Facebook is. They are trying to maintain this equilibrium where they extract enough that they keep their shareholders happy, but not so much that people leave. They’re now at the end of a long run of extremely bad choices. I’m not shorting Meta stock, but I think that they are on the path to becoming a kind of zombie — something like MySpace is today. You know, MySpace still exists. You can go to MySpace. It’s just AI-generated slop and and spam.
(Note: Meta didn’t respond to Nightcap’s request for comment.)
Nightcap:How are you feeling about the future of tech?
Doctorow:In terms of the future of enshittification, these platforms that have hollowed themselves out, where there’s just no value left in them except this kind of awful lock-in. It’s the old “we go broke a little, and then all at once.”
I do think there is reason to be hopeful. As a science fiction writer, I know that prediction is a mug’s game. But as an activist, I’m like, well, you take the weakest flank where you can make the biggest strategic advance, and you march on that flank. And there are a lot of weak flanks in global big tech.
I’d say the last one is the potential for an alliance between people who are angry about other kinds of monopolies, because it’s not just tech — people are really angry about grocery monopolies and oil monopolies, sea freight monopolies, eyeglass monopolies. One company, EssilorLuxottica, owns every eyewear brand you’ve ever heard of and every eyewear store you’ve ever shopped at, and they make more than 50% of the lenses, and they own EyeMed, the largest insurer in the world, and they’ve raised the price of glasses 1,000% in the last decade.
(EssilorLuxottica didn’t respond to Nightcap’s request for comment.)
So people are pissed off about monopolies. And if they can make a coalition, it’ll be like when we discovered the word “ecology” in the ’70s — we realized that just because you care about owls and I care about the ozone layer, it doesn’t mean we’re not caring about the same thing. Every time you see the world change all of a sudden, it’s because a new coalition has popped up."
3,Hate Speech Regulation,"There’s going to be even more harmful content on social media as Meta drops fact-checkers. What to tell your kids

---

Editor’s note:Kara Alaimo is an associate professor of communication at Fairleigh Dickinson University. Her book “Over the Influence:Why Social Media Is Toxic for Women and Girls — And How We Can Take It Back” was published in 2024 by Alcove Press. Follow her on Instagram, Facebook and Bluesky.
Many parents were already worried about their kids being exposed to false information and other harmful content on social media beforeMeta’s surprise decisionto drop its fact-checkers.
Now, there’s reason to fear things are going to get even worse.
On Tuesday, Metaannouncedit’s ending its fact-checking partnerships for Instagram and Facebook in the United States. Instead, users will be able to write “community notes” on problematic posts. Meta CEO Mark Zuckerbergacknowledgedthat, as a result, the company will catch less “bad stuff” posted on its platforms.
Related articleTeens spend most of their time on their phones. Here’s expert advice on what to do
It’s not like social media platforms were all vetted and had strong sourcing for users’ posts before. But Zuckerberg’s decision makes it even more important for children to be taught how to sort out what they should and should not believe on social media. Parents can also use this opportunity to talk to their kids about why they should never share or act on claims they see online without fact-checking them first.
Here’s what to teach them.
To figure out whether a social media post is accurate, the mainstream media is a good place to start. “Consider whether other credible, mainstream news outlets are reporting the same news,” said James P. Steyer, founder and CEO ofCommon Sense Media, a nonprofit organization that helps parents and teachers instill critical thinking skills in children. “If they’re not, it doesn’t mean it’s not true, but it does mean you should dig deeper.”
To learn how to understand media coverage, parents should encourage kids to “consume more news, not less,” said Dr. Jingsi Christina Wu, associate professor of media studies at Hofstra University on Long Island, New York, via email. You can do so by reading or watching the news together and then discussing it. Wu said the more children consume news, the more they gain the cognitive ability to interpret it.
Related articleWhat is ‘sharenting’? How parents could be harming their kids on social media
When evaluating posts, Steyer said kids should also be taught to consider who made the content, whether they appear trustworthy, what their motivations might be and who might benefit from or be hurt by it.
In particular, Wu said, kids should be told that “your favorite influencers are not experts.” Parents can explain that it’s “OK to watch your favorite TikTokers or YouTubers for their entertainment value or special experiences, but they are not credentialed experts on facts and they have their own biases about the world.”
Similarly, children (and their parents) shouldn’t assume something is true simply because it’s gotten a lot of views or likes. “Virality does not equal truth,” Wu warned. In fact, she said, “Fake news travels faster by taking advantage of human instincts for sharing abnormal stories.”
Looking for small errors in things such as spelling and grammar is another way to spot unreliable posts, Wu said. She also suggested encouraging kids to look at details in pictures and videos for signs they’ve been manipulated. For example, a hand with the wrong number of fingers could be a giveaway that artificial Intelligence generated it, she said.
Kids should also consider it a red flag if a piece of content provokes strong emotions in them, Steyer said. “Misinformation and disinformation are created to get extreme reactions out of people.”
Related articleAre ‘manfluencers’ raising our sons?
Children should be taught not to consume inaccurate or extremist content because algorithms are designed to show people what they think they like — so the more they watch or engage with particular types of posts, the more likely they are to be fed more content that is similar.
Kids should know that, when they consume content, creators often profit from their views, said Dr. Devorah Heitner, the Chicago-based author of “Growing Up in Public:Coming of Age in a Digital World.” This happensbecause higher view counts often allow creators to make more money from ads. It’s another reason to steer clear of content that is false or otherwise problematic.
When I speak to parents in schools about how to handle their kids’ social media use, I suggest consuming social media content about topics that interest their children together. For example, if a kid is interested in becoming a veterinarian, they can watch videos from zoos around the world. Then, even when the parent isn’t present, algorithms are likely to feed the child similar posts.
Wu said parents should also encourage their kids to talk to them when they’re unsure how to judge whether content is accurate. Even if parents suspect it’s fake, it’s not a good idea to say so right away. “Children might feel judged or dismissed if parents simply laugh things off or outright brush off all online content as fake or untrustworthy,” she warned.
Related articleHow teens view social media’s impact on their mental health
Instead, Wu suggested that parents do research with their children. “This approach keeps the dialogue open and also alleviates … the stress of being all-knowing at all times,” she said. “It also demonstrates to the kids that learning never stops and media literacy is a muscle that needs to be exercised.”
Thanks to Meta’s new policy, I expect that children will be exposed to even more dangerous content on social media. But parents can protect kids by teaching them how to evaluate what they see online, so they know what to believe and how to avoid problematic posts.
Get inspired by a weekly roundup on living well, made simple.Sign up for CNN’s Life, But Better newsletter for information and tools designed to improve your well-being."
4,Hate Speech Regulation,"Tech giants ramp up the battle against online hate speech in Europe. At home, some are pulling back

---

Two of America’s Big Tech companies are opening the door to more“free expression,”even if it means more hateful content. But in Europe, Big Tech companies are voluntarily cracking down.
It’s a reminder of just how divergent Europeans’ and Americans’ online experiences are becoming, as EU lawmakers forge ahead with tech safety and accountability legislation against an industry widely seen as too big and too out of control, while such proposals have languished, if not faced active resistance, on Capitol Hill.
Tech platforms including Meta’s Facebook and Instagram, X, Snapchat, TikTok, Twitch, LinkedIn and YouTube this week signed onto an updatedEuropean Union code of conductpromising to do more to combat online hate speech, which is often illegal in European countries.
Meanwhile, two of those same platforms — Meta and X — have made changes in the United States that they acknowledge could usher in more hateful speech, arguing that such changes promote freedom of speech and combat censorship. And across the industry, companies have shrunkteamswhose entire job was to ensure the safety of their platforms, including from people who seek to foment hate and violence.
The contrast is striking.
Related articleCalling women ‘household objects’ now permitted on Facebook after Meta updated its guidelines
As part of the EU agreement, the companies agree to allow “monitoring reporters” — non-profits or public organizations with expertise on hate speech — to review their platforms and to act quickly on most of the content they flag, the European Commission said Monday.
The new code of conduct is voluntary, but tech companies can use their compliance to demonstrate that they are meeting obligations legally required by theEU’s Digital Services Act (DSA), which, among other things, mandates Big Tech platforms take meaningful steps to reduce illegal and harmful content.
“In Europe there is no place for illegal hate, either offline or online,” Henna Virkkunen, the commission’s executive vice president for tech sovereignty, security and democracy, said in a statement, adding that the commitments will help “ensure a safe digital space for all.”
It’s one of a number of differences in US versus EU tech users’ online experiences that have accumulated over time, Isabelle Wright, director of technology and society at the Institute for Strategic Dialogue, told CNN.
“I think we’ve been heading in this direction for a while, but not just for hate speech, I think really for all categories of harm that most (other) Western nations cover in in their tech regulation,” Wright said. “It’s going to lead to an incredibly fractured information ecosystem between the US and essentially every other Western democracy.”
Meta and X did not respond to requests for comment.
To be sure, Silicon Valley’s efforts have always been far from perfect. Meta’s platforms have been accused of playing akey rolein the organization of the January 6, 2021, attack on the US Capitol andabetting genocidein Myanmar. And across the tech world, efforts to address harmful content like hate speech have always been targeted, at least to some extent, at placating advertisers obsessed with “brand safety,” terrified at the thought that their ads could be placed next to a comment section awash in inflammatory remarks and threats of violence. With advertising being the prime revenue generator for social media companies, the tastes of advertisers has historically set the tone.
But now even those efforts have been scaled back in the United States.
Elon Musk-owned X has seen an uptick in hate speech in recent years as it welcomed previously banned White supremacists and conspiracy peddlers back to the platform. Musk himself has also boosted racist conspiracies on the site.
And Meta earlier this month announced several majorcontent moderation policy changesin the United States, including scaling back its automated systems for removing content that violates its policies. The systems will now be focused on checking only for illegal and “high-severity” violations such as terrorism and child sexual exploitation.
Meta also updated its hateful conduct policy to roll back protections for certain groups, including women and LGBTQ+ people. Users of Meta’s platforms will now, for example, be able to refer to women as household objects and suggest that transgender people are mentally ill, without fear that their comments will be removed or restricted by Facebook’s moderation team. (A Meta spokesperson noted that the company would continue to prohibit slurs, as well as attacks against certain groups, such as those based on ethnicity, race and religion.)
The platforms’ US moves may reflect the changing American political environment, where many Republican leaders have equated content moderation with “censorship.”
Members of the incoming Donald Trump administration, including the nominee to lead the Federal Communications Commission, Brendan Carr, have also called for a reinterpretation of the tech immunity law Section 230. In essence, they want tech companies to be protected from lawsuits over what their users post only if they do little-to-no content moderation whatsoever.
Following Meta’s announcement earlier this month, Carrposteda gif of Jack Nicholson grinning and nodding in response to CNN’s Brian Stelter post on X with the news about the tech giant’s moderation policy.
When tech platforms announce changing policies or principles, Wright said, “the language they use to stand behind those indicates that they’ve put in, you know, a lot of a lot of thought and consultation into these processes. Yet when an administration changes, those principles seem to change like the wind in order to better align with the people who could potentially regulate them or disrupt their businesses.”
“I think what has become clear to the platforms is that the chances of any type of tech regulation in the US are slim to none,” Wright said.
But it isn’t just hate speech where Americans have a different experience. Europeans are protected in much broader ways, too.
Unlike Americans, Europeans are protected from having their personal demographic information, such as their race and political views, collected by tech companies without their consent, thanks to theGeneral Data Protection Regulation. Nor can Big Tech firms stop app developers from communicating cheaper, off-platform offers to users because of theDigital Markets Act. The DSA also provides EU users withgreater protectionsfrom targeted online ads. And Europeans may have less access to AI tools, including products fromAppleandMeta, because of privacy regulations and anEU lawaimed at safe and responsible development of the technology.
But that divergence has the potential to become less pronounced as tech leaders have cozied up to Trump in the hopes that the new administration will advance their interests.
Zuckerberg and Musk, as well as Google CEO Sundar Pichai, Apple CEO Tim Cook, Amazon founder Jeff Bezos, OpenAI CEO Sam Altman and TikTok CEO Shou Chew, were all seated prominently at Trump’s inauguration Monday.
Some of those Big Tech CEOs have already suggested they want Trump to pressure Europe into relaxing protections and regulations on the continent.
Cook issaid to haveraised the issue of European regulations in a meeting with Trump at Mar-a-Lago following the election. And Zuckerberg has expressly said he will seek Trump’s help in pushing back on safety rules from the EU and elsewhere.
In his policy announcement earlier this month, Zuckerberg said: “We’re going to work with President Trump to push back on governments around the world that are going after American companies and pushing to censor more.”"
5,Hate Speech Regulation,"Meta is getting rid of fact checkers. Zuckerberg acknowledged more harmful content will appear on the platforms now

---

In a number of sweeping changes that will significantly alter the way that posts, videos and other content are moderated online, Meta will adjust its content review policies on Facebook and Instagram, getting rid of fact checkers and replacing them with user-generated “community notes,” similar to Elon Musk’s X, CEO Mark Zuckerberg announced Tuesday.
The changes come just before President-elect Donald Trump is set to take office. Trump and other Republicans have lambasted Zuckerberg and Meta for what they view as censorship of right-wing voices.
“Fact checkers have been too politically biased and have destroyed more trust than they’ve created,” Zuckerberg said in avideo announcing the new policyTuesday. “What started as a movement to be more inclusive has increasingly been used to shut down opinions and shut out people with different ideas, and it’s gone too far.”
Zuckerberg, however, acknowledged a “tradeoff” in the new policy, noting more harmful content will appear on the platform as a result of the content moderation changes.
Meta’s newly appointed Chief of Global Affairs Joel Kaplan told Fox on Tuesday that Meta’s partnerships with third-party fact checkers were “well intentioned at the outset but there’s just been too much political bias in what they choose to fact check and how.”
Related articleUFC head Dana White joins Meta’s board, Mark Zuckerberg’s second key right-wing appointment in a week
The announcement comes amid a broader apparent ideological shift to the right within Meta’s top ranks, and as Zuckerberg seeks to improve his relationship with Trump before the president-elect takes office later this month. Just one day earlier, Meta announced Trump ally and UFC CEO Dana White would join its board, along with two other new directors. Meta has also said it will donate $1 million to Trump’s inaugural fund, and that Zuckerberg wants to take an “active role” in tech policy discussions.
Kaplan, a prominent Republican whowas elevatedto the company’s top policy job last week, acknowledged that the Tuesday announcement is directly related to the changing administration.
He said that there’s “no question that there has been a change over the last four years. We saw a lot of societal and political pressure, all in the direction of more content moderation, more censorship, and we’ve got a real opportunity. Now, we’ve got a new administration, and a new president coming in who are big defenders of free expression, and that makes a difference.”
Meta gave Trump’s team an advanced heads up that the moderation policy change was coming, a source familiar with the conversation told CNN.
During a press conference Tuesday at Mar-a-Lago, Trump said he watched Kaplan’s appearance on Fox and said Meta has “come a long way.”
“I watched their news conference, and I thought it was a very good news conference. I think they’ve, honestly, I think they’ve come a long way. Meta. Facebook. I think they’ve come a long way. I watched it, the man was very impressive,” Trump said in response to a question from CNN’s Steve Contorno.
Contorno asked if Trump thought the decision by Meta was a direct response to threats Trump has made to Zuckerberg in the past. “Probably. Yeah, probably,” Trump said.
Also following the announcement, Brendan Carr, who Trump has tapped to be chair of the Federal Communications Commission and who has railed onbig tech companies over “censorship,”posted a gif of Jack Nicholson grinning and nodding in response to CNN’s Brian Stelterposton X with the news.
The Real Facebook Oversight Board — an outside accountability organization, whose name is a play on the company’s official group, comprised of academics, lawyers and civil rights advocates including early Facebook investor Roger McNamee — said the policy changes represent Meta going “full MAGA.”
“Meta’s announcement today is a retreat from any sane and safe approach to content moderation,” the group said in a statement, calling the changes “political pandering.”
The moderation changes mark a stunning reversal in how Meta handles false and misleading claims on its platforms.
In 2016, the company launched an independent fact-checking program, in the wake of claims that it had failed to stop foreign actors from leveraging its platforms to spread disinformation and sow discord among Americans. In the years since, it continued to grapple with the spread of controversial content on its platform, such as misinformation about elections, anti-vaccination stories, violence and hate speech.
The company built up safety teams, introduced automated programs to filter out or reduce the visibility of false claims and instituted a sort of independent Supreme Court for tricky moderation decisions, known as the Oversight Board.
Although Meta’s fact checking partners repeatedly said they checked claims from both the right and left, Trump supporters and other conservatives have long claimed that the system restricted their voices.
“Anything I put on there about our president is generally only on for a few minutes and then suddenly they’re fact checking me saying this that and the other thing, which I know is not true. Their fact checker’s wrong,” one Trump supportertold CNNat a rally in 2020.
But now, Zuckerberg is following in the footsteps of fellow social media leader Musk who, after acquiring X, then known as Twitter, in 2022, dismantled the company’s fact-checking teams and made user-generated context labels, called “community notes,” the platform’s only method of correcting false claims.
Starting in the United States, Meta says it is ending its partnership with third-party fact checkers and instituting similar community notes across its platforms, including Facebook, Instagram and Threads.
“I think Elon has played an incredibly important role in moving the debate and and getting people refocused on free expression, and that’s been really constructive and productive,” Kaplan said.
X CEO Linda Yaccarino responded to Meta’s move in an XpostTuesday, calling the community notes model “profoundly successful while keeping freedom of speech sacred. It’s a smart move by Zuck and something I expect other platforms will follow now that X has shown how powerful it is.” Musk himselfcalledthe Meta change “cool.”
Meta also plans to adjust its automated systems that scan for policy violations, which it says have resulted in “too much content being censored that shouldn’t have been.” The systems will now be focused on checking only for illegal and “high-severity” violations such as terrorism, child sexual exploitation, drugs, fraud and scams. Other concerns will have to be reported by users before the company evaluates them.
Zuckerberg said Tuesday that Meta’s complex systems to moderate content have mistakenly resulted in too much non-violating content being removed from the platform. For example, if the systems get something wrong 1% of the time, that could represent millions of the company’s more than 2 billion users.
“We’ve reached a point where it’s just too many mistakes and too much censorship,” Zuckerberg said.
But Zuckerberg acknowledged that the new policy could create new problems for content moderation.
“The reality is this is a tradeoff,” he said in the video. “It means that we’re going to catch less bad stuff, but we’ll also reduce the number of innocent people’s posts and accounts that we accidentally take down.”
The company is also getting rid of content restrictions on certain topics, such as immigration and gender identity, and rolling back limits on how much politics-related content users see in their feeds.
As part of the changes, Meta will move its trust and safety teams responsible for content policies from California to Texas and other US locations. “I think that will help us build trust to do this work in places where there is less concern about the bias of our teams,” Zuckerberg said.
This story has been updated with additional developments and context.
– CNN’s Kate Sullivan contributed to this report."
